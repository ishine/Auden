exp_dir:
hydra:
  run:
    dir: ${exp_dir}/logs/${now:%Y-%m-%d}/${now:%H-%M-%S}  # Force Hydra output (logs, etc.) into your experiment dir

model:
  model_type: audio-llm 
  audio_encoder:
    model_type: zipformer
    pretrained_model: null
    frozen: True
  llm:
    model_type: qwen2
    pretrained_model: Qwen/Qwen2.5-7B-Instruct
    use_flash_attn: False
    frozen: True
  audio_token: <|AUDIO|> 
  audio_encoder_projector_ds_rate: 4 # 4 * 4 = 16 for zipformer and 2 * 8 = 16 for others; i.e. 100hz fbank --> 6.25Hz LLM input token
  tag_audio_boundary: False
  exclude_from_checkpoint: null

trainer:
  optimizer: 
    type: "adam"
    lr: 0.001 # better than 1e-4 from experiments
  scheduler: 
    type: "eden"
    lr_epochs: 3.5 # Number of epochs that affects how rapidly the learning rate decreases.
    lr_batches: 7500 # Number of steps that affects how rapidly the learning rate decreases. We suggest not to change this.
    warmup_batches: 500 # lr warmup steps
    lr_steps_per_epoch: 0 # recommend to adjust this value when you do use_infinite_dataset=True to get exact learning rate schedule as usual. Set it close to your estimated number of steps per epoch
  num_epochs: 30
  start_epoch: 1
  num_steps: 100000
  start_batch: 0
  keep_last_k: 30 # save last_k checkpoints on disk
  use_averaged_model: True
  log_interval: 50
  average_period: 200 # how rapidly the averaged_model is averaged and saved
  reset_interval: 200 # moving average interval for info tracker
  valid_interval: 1000
  save_every_n: 4 # save checkpoint every (n * valid_interval) steps
  use_fp16: True
  tensorboard: True

data:
  train_data_config: configs/data_configs/train_data_config.yaml
  valid_data_config: configs/data_configs/valid_data_config.yaml
  on_the_fly_feats: True
  feature: fbank
  sampling_rate: 16000
  use_infinite_dataset: True # the iterator of each dataset will never be exhausted so there will only be steps, no epochs
  data_augmentation:
    enable_spec_aug: True
    enable_musan: False
    musan: /apdcephfs_cq12/share_302080740/data/asr_train_data/manifests/musan/musan_cuts.jsonl.gz
    enable_speed_perturb: False
  sampler:
    type: bucketing_sampler
    num_buckets: 30
    max_duration: 80 # total secs of speech within a minibatch
    shuffle: True
    drop_last: True
  text_normalization: True
  pad_to_30s: False

prompt_file: configs/prompt.yaml